# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DnyuEsUynqKsVYzb3JhxRBLuAu2cngf-
"""

import pandas as pd
import numpy as np
import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import joblib  # For saving/loading models

# Upload CSV file using Streamlit file uploader
uploaded_file = st.file_uploader("Upload Mushroom Dataset", type="csv")
if uploaded_file is not None:
    # Load the data
    df = pd.read_csv(uploaded_file)
    st.write("Data loaded successfully!")

    # Data Preprocessing
    # Check for missing values and handle them
    df.fillna(df.mode().iloc[0], inplace=True)

    # Convert categorical variables to numeric using one-hot encoding
    df = pd.get_dummies(df)

    # Split the dataset into features and target
    X = df.drop(columns=['class_e', 'class_p'])  # Drop the one-hot encoded class columns
    y = df['class_e']  # Assuming we use 'class_e' for edible (you can choose 'class_p' for poisonous)

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Initialize and train the model
    rf = RandomForestClassifier()
    rf.fit(X_train, y_train)

    # Save the trained model
    joblib.dump(rf, 'random_forest_model.pkl')

    # Evaluate the model
    rf_preds = rf.predict(X_test)
    accuracy = accuracy_score(y_test, rf_preds)
    st.write(f"Model Accuracy: {accuracy * 100:.2f}%")

    # Visualize feature importances (optional)
    feature_importances = pd.DataFrame(rf.feature_importances_, index=X.columns, columns=["Importance"])
    st.write("Feature Importance:")
    st.write(feature_importances)

    # Load the trained model for prediction
    rf = joblib.load('random_forest_model.pkl')

    # Feature scaling for input data
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Display feature input widgets for user prediction
    st.title("Mushroom Classification")
    st.write("Enter the features of the mushroom to predict whether it's edible or poisonous.")

    # List of features (replace with actual ones used in your dataset)
    feature_names = X.columns.tolist()
    input_values = {}

    for feature in feature_names:
        # Determine if the feature is categorical or numeric
        if df[feature].dtype == 'object':
            # Assuming categorical features
            unique_values = df[feature].unique()
            input_values[feature] = st.selectbox(f"{feature}", unique_values)
        else:
            # For numeric features
            input_values[feature] = st.number_input(f"{feature}", value=0.0)

    # Prediction button
    if st.button('Predict'):
        # Create input data for prediction
        input_data = pd.DataFrame([input_values])

        # Apply scaling (same as during training)
        input_data_scaled = scaler.transform(input_data)

        # Make the prediction
        prediction = rf.predict(input_data_scaled)[0]

        # Display the prediction
        result = "Edible" if prediction == 1 else "Poisonous"
        st.write(f"The prediction is: {result}")